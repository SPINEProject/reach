#
# Main Configuration file for Reach.
#

# Default top-level root directory for input and output files and subdirectories.
# All other paths are based on this path but any or all can be changed individually:
rootDir = /home/sthumsi/enter/reach

//rootDir = /Users/shraddha/datascience/reach
# this is where the brat standoff and text files are dumped
# if this directory does not exist it will be created
bratDir = ${rootDir}/main/src/main/scala/org/clulab/reach/brat

# this is where the context files will be stored
# if this directory does not exist it will be created
contextDir = ${rootDir}/context
contextResourceDir = ${rootDir}/main/src/main/resources/org/clulab/context

# this is where the output files containing the extracted mentions will be stored
# if this directory does not exist it will be created
outDir = ${rootDir}/output

# this is the directory that stores the raw nxml, .csv, and/or .tsv files
# this directory *must* exist
papersDir = ${rootDir}/papers


# the encoding of input and output files
encoding = "utf-8"

# this is a list of sections that we should ignore
//ignoreSections = ["references", "materials", "materials|methods", "methods", "supplementary-material"]
ignoreSections = []
# the output formats for mentions:
# "arizona" (column-based, one file per paper)
# "cmu" (column-based, one file per paper)
# "fries" (multiple JSON files per paper)
# "serial-json" (JSON serialization of mentions data structures. LARGE output!)
# "text" (non-JSON textual format)
outputTypes = ["fries", "arizona", "cmu", "serial-json", "text"]

# number of simultaneous threads to use for parallelization
threadLimit = 4

# verbose logging
verbose = true

# whether or not assembly should be run
withAssembly = false


# context engine configuration
// The value for SVMPolicy has been assigned in ContextEngineFactory.scala
contextEngine {
  type = SVMPolicy
  //type = Policy4
  params = {

     bound = 15
     trainedSvmPath = ${contextResourceDir}/svmFeatures/svmTrainedModel.dat
    allFeatures = ${contextResourceDir}/svmFeatures/allFeaturesFile.txt
    hardCodedFeatures = ${contextResourceDir}/svmFeatures/hardCodedFeatures.txt
  }
}

policy4Params {
  mentionsOutputFile = ${contextResourceDir}/policy4/
}

svmContext {
  untrainedSVMPath = ${contextResourceDir}/svmCrossVal/svmUntrainedModel.dat
  groupedFeatures = ${contextResourceDir}/svmFeatures/grouped_features.csv.gz
  labelFile = ${contextResourceDir}/svmCrossVal/labels.csv
  labelFileOldDataset = ${contextResourceDir}/svmCrossVal/labels_old_dataset.csv
  folds = ${contextResourceDir}/svmCrossVal/cv_folds_val_4.csv
  outputDirForAnnotations = ${contextResourceDir}/outputDirForAnnotations/
  cvmetricsFilePath = ${contextResourceDir}/svmCrossVal/cvMetricsPerPaper.csv
}

polarityContext{
  genericFileDir = ${contextResourceDir}/polarity/genericFileResources/
  outputForPolarityAnalysisDir = ${contextResourceDir}/polarity/genericFileResources/outputPerPaper/
  outputForPolarityAnalysisFile = ${contextResourceDir}/polarity/genericFileResources/outputPerPaper/output_for_pretty_table.txt
  aggrRowWrittenToFilePerPaper = ${contextResourceDir}/polarity/genericFileResources/aggrRowsWrittenToFile/
  aggrRowWrittenToFilePerPaperNewAnnotations = ${contextResourceDir}/polarity/genericFileResources/aggrRowsWrittenToFile/newAnnotations/
  eventsFilesDir = ${contextResourceDir}/polarity/events_files/
}



# grounding configuration
grounding: {
  # List of AdHoc grounding files to insert, in order, into the grounding search sequence.
  # Each element of the list is a map of KB filename and optional meta info (not yet used):
  #   example: { kb: "adhoc.tsv", source: "NMZ at CMU" }
  adHocFiles: [
    { kb: "NER-Grounding-Override.tsv.gz", source: "MITRE/NMZ/BG feedback overrides" }
  ]

  # flag to turn off the influence of species on grounding
  overrideSpecies = true
}

# logging configuration
logging {
  # defines project-wide logging level
  loglevel = INFO
  logfile = ${outDir}/reach.log
}

# Processor Annotator choice and configuration
processorAnnotator {
  // select which processor annotator type to use: "bionlp", "clu", "clubio", or "server"
  type = "bionlp"
}

# restart configuration
restart {
  # restart allows batch jobs to skip over input files already successfully processed
  useRestart = false
  # restart log is one filename per line list of input files already successfully processed
  logfile = ${outDir}/restart.log
}

# ReadPapers
ReadPapers.papersDir = src/test/resources/inputs/nxml/
ReadPapers.serializedPapers = mentions.ser
